{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "korean-wednesday",
      "metadata": {
        "id": "korean-wednesday"
      },
      "source": [
        "# Recurrent Neural Networks\n",
        "You should build an end-to-end machine learning pipeline using a recurrent neural network model. In particular, you should do the following:\n",
        "- Load the `jena climate` dataset using [Pandas](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html). You can find this dataset in the [keras repository](https://keras.io/examples/timeseries/timeseries_weather_forecasting/).\n",
        "- Split the dataset into training, validation, and test sets. Note that you cannot split time series using [Scikit-Learn](https://keras.io/examples/timeseries/timeseries_weather_forecasting/).\n",
        "- Build an end-to-end machine learning pipeline, including a [recurrent neural network](https://keras.io/examples/timeseries/timeseries_weather_forecasting/) model.\n",
        "- Optimize your pipeline by validating your design decisions.\n",
        "- Test the best pipeline on the test set and report various [evaluation metrics](https://scikit-learn.org/0.15/modules/model_evaluation.html).  \n",
        "- Check the documentation to identify the most important hyperparameters, attributes, and methods of the model. Use them in practice."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "data_path = '/content/jena_climate_2009_2016.csv'\n",
        "df = pd.read_csv(data_path)\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "id": "PU3_Tykh3cJj",
        "outputId": "e433537a-3ed5-4e6d-c3de-2adac5477cf2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "PU3_Tykh3cJj",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             Date Time  p (mbar)  T (degC)  Tpot (K)  Tdew (degC)  rh (%)  \\\n",
            "0  01.01.2009 00:10:00    996.52     -8.02    265.40        -8.90    93.3   \n",
            "1  01.01.2009 00:20:00    996.57     -8.41    265.01        -9.28    93.4   \n",
            "2  01.01.2009 00:30:00    996.53     -8.51    264.91        -9.31    93.9   \n",
            "3  01.01.2009 00:40:00    996.51     -8.31    265.12        -9.07    94.2   \n",
            "4  01.01.2009 00:50:00    996.51     -8.27    265.15        -9.04    94.1   \n",
            "\n",
            "   VPmax (mbar)  VPact (mbar)  VPdef (mbar)  sh (g/kg)  H2OC (mmol/mol)  \\\n",
            "0          3.33          3.11          0.22       1.94             3.12   \n",
            "1          3.23          3.02          0.21       1.89             3.03   \n",
            "2          3.21          3.01          0.20       1.88             3.02   \n",
            "3          3.26          3.07          0.19       1.92             3.08   \n",
            "4          3.27          3.08          0.19       1.92             3.09   \n",
            "\n",
            "   rho (g/m**3)  wv (m/s)  max. wv (m/s)  wd (deg)  \n",
            "0       1307.75      1.03           1.75     152.3  \n",
            "1       1309.80      0.72           1.50     136.1  \n",
            "2       1310.24      0.19           0.63     171.6  \n",
            "3       1309.19      0.34           0.50     198.0  \n",
            "4       1309.00      0.32           0.63     214.3  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_samples = len(df)\n",
        "train_split = int(num_samples * 0.7)\n",
        "val_split = int(num_samples * 0.9)\n",
        "\n",
        "train_data = df[:train_split]\n",
        "val_data = df[train_split:val_split]\n",
        "test_data = df[val_split:]\n"
      ],
      "metadata": {
        "id": "cTa07P283rRJ"
      },
      "id": "cTa07P283rRJ",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns)\n"
      ],
      "metadata": {
        "id": "uqEfgr5D4ZVd",
        "outputId": "0111f0a5-98fe-44e3-d4a0-c3aaeda8b29b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "uqEfgr5D4ZVd",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Date Time', 'p (mbar)', 'T (degC)', 'Tpot (K)', 'Tdew (degC)',\n",
            "       'rh (%)', 'VPmax (mbar)', 'VPact (mbar)', 'VPdef (mbar)', 'sh (g/kg)',\n",
            "       'H2OC (mmol/mol)', 'rho (g/m**3)', 'wv (m/s)', 'max. wv (m/s)',\n",
            "       'wd (deg)'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming first column is timestamp, exclude it\n",
        "numeric_train_data = train_data.iloc[:, 1:]  # select all columns except the first\n",
        "\n",
        "mean = numeric_train_data.mean()\n",
        "std = numeric_train_data.std()\n",
        "\n",
        "# Normalize only numeric columns\n",
        "train_data.iloc[:, 1:] = (train_data.iloc[:, 1:] - mean) / std\n",
        "val_data.iloc[:, 1:] = (val_data.iloc[:, 1:] - mean) / std\n",
        "test_data.iloc[:, 1:] = (test_data.iloc[:, 1:] - mean) / std\n"
      ],
      "metadata": {
        "id": "a8F-tTkc4bd5"
      },
      "id": "a8F-tTkc4bd5",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Date Time'] = pd.to_datetime(df['Date Time'], format='%d.%m.%Y %H:%M:%S')\n"
      ],
      "metadata": {
        "id": "YKakef1r4iL8"
      },
      "id": "YKakef1r4iL8",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming timestamp is first column, exclude it from normalization\n",
        "mean = train_data.iloc[:, 1:].mean()\n",
        "std = train_data.iloc[:, 1:].std()\n",
        "\n",
        "train_data.iloc[:, 1:] = (train_data.iloc[:, 1:] - mean) / std\n",
        "val_data.iloc[:, 1:] = (val_data.iloc[:, 1:] - mean) / std\n",
        "test_data.iloc[:, 1:] = (test_data.iloc[:, 1:] - mean) / std\n"
      ],
      "metadata": {
        "id": "0cTUeadZ3sqi"
      },
      "id": "0cTUeadZ3sqi",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def create_tf_dataset(data, lookback, delay, step, batch_size=128):\n",
        "    data = data.values[:, 1:]  # exclude timestamp column\n",
        "    targets = data[:, 0]  # e.g. first numeric column (temperature)\n",
        "\n",
        "    # Inputs: sliding windows of shape (lookback/step, features)\n",
        "    inputs = tf.keras.utils.timeseries_dataset_from_array(\n",
        "        data=data[:-delay],\n",
        "        targets=targets[lookback + delay:],\n",
        "        sequence_length=lookback // step,\n",
        "        sequence_stride=1,\n",
        "        sampling_rate=step,\n",
        "        batch_size=batch_size\n",
        "    )\n",
        "    return inputs\n"
      ],
      "metadata": {
        "id": "lF10JriY5LqF"
      },
      "id": "lF10JriY5LqF",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data.dtypes)          # Confirm numeric columns\n",
        "print(train_data.isnull().sum())  # Check for missing values\n"
      ],
      "metadata": {
        "id": "iUOTAuw35nuY",
        "outputId": "86bd84b2-8912-40fb-bf56-fc25e2d56258",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "iUOTAuw35nuY",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Date Time           object\n",
            "p (mbar)           float64\n",
            "T (degC)           float64\n",
            "Tpot (K)           float64\n",
            "Tdew (degC)        float64\n",
            "rh (%)             float64\n",
            "VPmax (mbar)       float64\n",
            "VPact (mbar)       float64\n",
            "VPdef (mbar)       float64\n",
            "sh (g/kg)          float64\n",
            "H2OC (mmol/mol)    float64\n",
            "rho (g/m**3)       float64\n",
            "wv (m/s)           float64\n",
            "max. wv (m/s)      float64\n",
            "wd (deg)           float64\n",
            "dtype: object\n",
            "Date Time          0\n",
            "p (mbar)           0\n",
            "T (degC)           0\n",
            "Tpot (K)           0\n",
            "Tdew (degC)        0\n",
            "rh (%)             0\n",
            "VPmax (mbar)       0\n",
            "VPact (mbar)       0\n",
            "VPdef (mbar)       0\n",
            "sh (g/kg)          0\n",
            "H2OC (mmol/mol)    0\n",
            "rho (g/m**3)       0\n",
            "wv (m/s)           0\n",
            "max. wv (m/s)      0\n",
            "wd (deg)           0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = train_data.fillna(method='ffill').fillna(method='bfill')\n",
        "val_data = val_data.fillna(method='ffill').fillna(method='bfill')\n",
        "test_data = test_data.fillna(method='ffill').fillna(method='bfill')\n"
      ],
      "metadata": {
        "id": "YdWaB1zf5q0J",
        "outputId": "acf53f43-19d7-4c0a-a104-1b3cd2366620",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "YdWaB1zf5q0J",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-1135443180>:1: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  train_data = train_data.fillna(method='ffill').fillna(method='bfill')\n",
            "<ipython-input-9-1135443180>:2: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  val_data = val_data.fillna(method='ffill').fillna(method='bfill')\n",
            "<ipython-input-9-1135443180>:3: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  test_data = test_data.fillna(method='ffill').fillna(method='bfill')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_tf_dataset(data, lookback, delay, step, batch_size=128):\n",
        "    # Exclude timestamp column\n",
        "    data_array = data.iloc[:, 1:].to_numpy(dtype=np.float32)\n",
        "    targets = data_array[:, 0]  # example target: first numeric column\n",
        "\n",
        "    dataset = tf.keras.utils.timeseries_dataset_from_array(\n",
        "        data=data_array[:-delay],\n",
        "        targets=targets[lookback + delay:],\n",
        "        sequence_length=lookback // step,\n",
        "        sequence_stride=1,\n",
        "        sampling_rate=step,\n",
        "        batch_size=batch_size\n",
        "    )\n",
        "    return dataset\n"
      ],
      "metadata": {
        "id": "Fx_bmPJB50tl"
      },
      "id": "Fx_bmPJB50tl",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop timestamp column for normalization and dataset creation\n",
        "# (Assuming it is first column)\n",
        "\n",
        "# Fill missing values\n",
        "train_data = train_data.fillna(method='ffill').fillna(method='bfill')\n",
        "val_data = val_data.fillna(method='ffill').fillna(method='bfill')\n",
        "test_data = test_data.fillna(method='ffill').fillna(method='bfill')\n",
        "\n",
        "# Normalize numeric columns only (exclude timestamp)\n",
        "mean = train_data.iloc[:, 1:].mean()\n",
        "std = train_data.iloc[:, 1:].std()\n",
        "\n",
        "train_data.iloc[:, 1:] = (train_data.iloc[:, 1:] - mean) / std\n",
        "val_data.iloc[:, 1:] = (val_data.iloc[:, 1:] - mean) / std\n",
        "test_data.iloc[:, 1:] = (test_data.iloc[:, 1:] - mean) / std\n"
      ],
      "metadata": {
        "id": "kaH87lQX52Af",
        "outputId": "6f55f759-e3ae-407c-b797-dd1ec514c4f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "kaH87lQX52Af",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-3502151183>:5: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  train_data = train_data.fillna(method='ffill').fillna(method='bfill')\n",
            "<ipython-input-11-3502151183>:6: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  val_data = val_data.fillna(method='ffill').fillna(method='bfill')\n",
            "<ipython-input-11-3502151183>:7: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  test_data = test_data.fillna(method='ffill').fillna(method='bfill')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "batch_size = 128\n",
        "lookback = 720\n",
        "delay = 72\n",
        "step = 6\n",
        "\n",
        "train_dataset = create_tf_dataset(train_data, lookback, delay, step, batch_size)\n",
        "val_dataset = create_tf_dataset(val_data, lookback, delay, step, batch_size)\n",
        "test_dataset = create_tf_dataset(test_data, lookback, delay, step, batch_size)\n"
      ],
      "metadata": {
        "id": "d5YPEKz03wKQ"
      },
      "id": "d5YPEKz03wKQ",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "# Assume lookback, step, etc. defined as before\n",
        "\n",
        "# input_shape = (sequence_length, number_of_features)\n",
        "input_shape = (lookback // step, train_data.shape[1] - 1)  # exclude timestamp col\n",
        "\n",
        "model = Sequential([\n",
        "    LSTM(32, input_shape=input_shape),\n",
        "    Dropout(0.2),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='mae', metrics=['mae'])\n",
        "\n",
        "# Train using the tf.data.Dataset objects, not numpy arrays\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=10,\n",
        "    validation_data=val_dataset\n",
        ")\n",
        "\n",
        "# Evaluate on test dataset\n",
        "model.evaluate(test_dataset)\n"
      ],
      "metadata": {
        "id": "xEpoYG_W4Bo1",
        "outputId": "c7648b78-9a68-4bd6-b50f-9b5cdf3a6fc9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "xEpoYG_W4Bo1",
      "execution_count": 13,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m2294/2294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 79ms/step - loss: 0.4585 - mae: 0.4585 - val_loss: 0.3806 - val_mae: 0.3806\n",
            "Epoch 2/10\n",
            "\u001b[1m2294/2294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 78ms/step - loss: 0.3631 - mae: 0.3631 - val_loss: 0.3476 - val_mae: 0.3476\n",
            "Epoch 3/10\n",
            "\u001b[1m2294/2294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 80ms/step - loss: 0.3431 - mae: 0.3431 - val_loss: 0.3366 - val_mae: 0.3366\n",
            "Epoch 4/10\n",
            "\u001b[1m2294/2294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 87ms/step - loss: 0.3326 - mae: 0.3326 - val_loss: 0.3315 - val_mae: 0.3315\n",
            "Epoch 5/10\n",
            "\u001b[1m2294/2294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 77ms/step - loss: 0.3269 - mae: 0.3269 - val_loss: 0.3281 - val_mae: 0.3281\n",
            "Epoch 6/10\n",
            "\u001b[1m2294/2294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 78ms/step - loss: 0.3216 - mae: 0.3216 - val_loss: 0.3235 - val_mae: 0.3235\n",
            "Epoch 7/10\n",
            "\u001b[1m2294/2294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 78ms/step - loss: 0.3166 - mae: 0.3166 - val_loss: 0.3233 - val_mae: 0.3233\n",
            "Epoch 8/10\n",
            "\u001b[1m2294/2294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 79ms/step - loss: 0.3138 - mae: 0.3138 - val_loss: 0.3219 - val_mae: 0.3219\n",
            "Epoch 9/10\n",
            "\u001b[1m2294/2294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 77ms/step - loss: 0.3109 - mae: 0.3109 - val_loss: 0.3190 - val_mae: 0.3190\n",
            "Epoch 10/10\n",
            "\u001b[1m2294/2294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 87ms/step - loss: 0.3093 - mae: 0.3093 - val_loss: 0.3197 - val_mae: 0.3197\n",
            "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - loss: 0.2367 - mae: 0.2367\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.2547207176685333, 0.2547207176685333]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_dataset)"
      ],
      "metadata": {
        "id": "toGujtElgXsG",
        "outputId": "cdc5b48a-7b0d-40d2-e3f3-ba6e3a2894ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "toGujtElgXsG",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 36ms/step - loss: 0.2553 - mae: 0.2553\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.27107036113739014, 0.27107036113739014]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_mae = model.evaluate(test_dataset)\n",
        "print(f'Test MAE: {test_mae}')\n"
      ],
      "metadata": {
        "id": "mIgvogTK4F2P",
        "outputId": "2a0a15fd-8409-43e4-cfd8-b80de1f363e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "mIgvogTK4F2P",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m323/323\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - loss: 0.2553 - mae: 0.2553\n",
            "Test MAE: 0.27107036113739014\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "mae = mean_absolute_error(y_true, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "\n",
        "print(f\"📊 Final Evaluation Metrics:\")\n",
        "print(f\"MAE : {mae:.4f}\")\n",
        "print(f\"RMSE: {rmse:.4f}\")\n"
      ],
      "metadata": {
        "id": "5e8aKj3LhEzU",
        "outputId": "8bcd0e4b-fc55-4bb9-e731-4ab7c52ffa5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "5e8aKj3LhEzU",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Final Evaluation Metrics:\n",
            "MAE : 0.2711\n",
            "RMSE: 0.3532\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}