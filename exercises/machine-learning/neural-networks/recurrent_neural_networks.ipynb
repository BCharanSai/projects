{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "korean-wednesday",
      "metadata": {
        "id": "korean-wednesday"
      },
      "source": [
        "# Recurrent Neural Networks\n",
        "You should build an end-to-end machine learning pipeline using a recurrent neural network model. In particular, you should do the following:\n",
        "- Load the `jena climate` dataset using [Pandas](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html). You can find this dataset in the [keras repository](https://keras.io/examples/timeseries/timeseries_weather_forecasting/).\n",
        "- Split the dataset into training, validation, and test sets. Note that you cannot split time series using [Scikit-Learn](https://keras.io/examples/timeseries/timeseries_weather_forecasting/).\n",
        "- Build an end-to-end machine learning pipeline, including a [recurrent neural network](https://keras.io/examples/timeseries/timeseries_weather_forecasting/) model.\n",
        "- Optimize your pipeline by validating your design decisions.\n",
        "- Test the best pipeline on the test set and report various [evaluation metrics](https://scikit-learn.org/0.15/modules/model_evaluation.html).  \n",
        "- Check the documentation to identify the most important hyperparameters, attributes, and methods of the model. Use them in practice."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "data_path = '/content/jena_climate_2009_2016.csv'\n",
        "df = pd.read_csv(data_path)\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "id": "PU3_Tykh3cJj",
        "outputId": "ce813fab-e44d-447f-a487-2b40305556f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "PU3_Tykh3cJj",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             Date Time  p (mbar)  T (degC)  Tpot (K)  Tdew (degC)  rh (%)  \\\n",
            "0  01.01.2009 00:10:00    996.52     -8.02    265.40        -8.90    93.3   \n",
            "1  01.01.2009 00:20:00    996.57     -8.41    265.01        -9.28    93.4   \n",
            "2  01.01.2009 00:30:00    996.53     -8.51    264.91        -9.31    93.9   \n",
            "3  01.01.2009 00:40:00    996.51     -8.31    265.12        -9.07    94.2   \n",
            "4  01.01.2009 00:50:00    996.51     -8.27    265.15        -9.04    94.1   \n",
            "\n",
            "   VPmax (mbar)  VPact (mbar)  VPdef (mbar)  sh (g/kg)  H2OC (mmol/mol)  \\\n",
            "0          3.33          3.11          0.22       1.94             3.12   \n",
            "1          3.23          3.02          0.21       1.89             3.03   \n",
            "2          3.21          3.01          0.20       1.88             3.02   \n",
            "3          3.26          3.07          0.19       1.92             3.08   \n",
            "4          3.27          3.08          0.19       1.92             3.09   \n",
            "\n",
            "   rho (g/m**3)  wv (m/s)  max. wv (m/s)  wd (deg)  \n",
            "0       1307.75      1.03           1.75     152.3  \n",
            "1       1309.80      0.72           1.50     136.1  \n",
            "2       1310.24      0.19           0.63     171.6  \n",
            "3       1309.19      0.34           0.50     198.0  \n",
            "4       1309.00      0.32           0.63     214.3  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_samples = len(df)\n",
        "train_split = int(num_samples * 0.7)\n",
        "val_split = int(num_samples * 0.9)\n",
        "\n",
        "train_data = df[:train_split]\n",
        "val_data = df[train_split:val_split]\n",
        "test_data = df[val_split:]\n"
      ],
      "metadata": {
        "id": "cTa07P283rRJ"
      },
      "id": "cTa07P283rRJ",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns)\n"
      ],
      "metadata": {
        "id": "uqEfgr5D4ZVd",
        "outputId": "f5e56e80-aa2e-493a-e4a6-2ecb3bf0d423",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "uqEfgr5D4ZVd",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Date Time', 'p (mbar)', 'T (degC)', 'Tpot (K)', 'Tdew (degC)',\n",
            "       'rh (%)', 'VPmax (mbar)', 'VPact (mbar)', 'VPdef (mbar)', 'sh (g/kg)',\n",
            "       'H2OC (mmol/mol)', 'rho (g/m**3)', 'wv (m/s)', 'max. wv (m/s)',\n",
            "       'wd (deg)'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming first column is timestamp, exclude it\n",
        "numeric_train_data = train_data.iloc[:, 1:]  # select all columns except the first\n",
        "\n",
        "mean = numeric_train_data.mean()\n",
        "std = numeric_train_data.std()\n",
        "\n",
        "# Normalize only numeric columns\n",
        "train_data.iloc[:, 1:] = (train_data.iloc[:, 1:] - mean) / std\n",
        "val_data.iloc[:, 1:] = (val_data.iloc[:, 1:] - mean) / std\n",
        "test_data.iloc[:, 1:] = (test_data.iloc[:, 1:] - mean) / std\n"
      ],
      "metadata": {
        "id": "a8F-tTkc4bd5"
      },
      "id": "a8F-tTkc4bd5",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Date Time'] = pd.to_datetime(df['Date Time'], format='%d.%m.%Y %H:%M:%S')\n"
      ],
      "metadata": {
        "id": "YKakef1r4iL8"
      },
      "id": "YKakef1r4iL8",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming timestamp is first column, exclude it from normalization\n",
        "mean = train_data.iloc[:, 1:].mean()\n",
        "std = train_data.iloc[:, 1:].std()\n",
        "\n",
        "train_data.iloc[:, 1:] = (train_data.iloc[:, 1:] - mean) / std\n",
        "val_data.iloc[:, 1:] = (val_data.iloc[:, 1:] - mean) / std\n",
        "test_data.iloc[:, 1:] = (test_data.iloc[:, 1:] - mean) / std\n"
      ],
      "metadata": {
        "id": "0cTUeadZ3sqi"
      },
      "id": "0cTUeadZ3sqi",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def create_tf_dataset(data, lookback, delay, step, batch_size=128):\n",
        "    data = data.values[:, 1:]  # exclude timestamp column\n",
        "    targets = data[:, 0]  # e.g. first numeric column (temperature)\n",
        "\n",
        "    # Inputs: sliding windows of shape (lookback/step, features)\n",
        "    inputs = tf.keras.utils.timeseries_dataset_from_array(\n",
        "        data=data[:-delay],\n",
        "        targets=targets[lookback + delay:],\n",
        "        sequence_length=lookback // step,\n",
        "        sequence_stride=1,\n",
        "        sampling_rate=step,\n",
        "        batch_size=batch_size\n",
        "    )\n",
        "    return inputs\n"
      ],
      "metadata": {
        "id": "lF10JriY5LqF"
      },
      "id": "lF10JriY5LqF",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data.dtypes)          # Confirm numeric columns\n",
        "print(train_data.isnull().sum())  # Check for missing values\n"
      ],
      "metadata": {
        "id": "iUOTAuw35nuY",
        "outputId": "23277cc1-78b9-4474-e8df-82066c854128",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "iUOTAuw35nuY",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Date Time           object\n",
            "p (mbar)           float64\n",
            "T (degC)           float64\n",
            "Tpot (K)           float64\n",
            "Tdew (degC)        float64\n",
            "rh (%)             float64\n",
            "VPmax (mbar)       float64\n",
            "VPact (mbar)       float64\n",
            "VPdef (mbar)       float64\n",
            "sh (g/kg)          float64\n",
            "H2OC (mmol/mol)    float64\n",
            "rho (g/m**3)       float64\n",
            "wv (m/s)           float64\n",
            "max. wv (m/s)      float64\n",
            "wd (deg)           float64\n",
            "dtype: object\n",
            "Date Time          0\n",
            "p (mbar)           0\n",
            "T (degC)           0\n",
            "Tpot (K)           0\n",
            "Tdew (degC)        0\n",
            "rh (%)             0\n",
            "VPmax (mbar)       0\n",
            "VPact (mbar)       0\n",
            "VPdef (mbar)       0\n",
            "sh (g/kg)          0\n",
            "H2OC (mmol/mol)    0\n",
            "rho (g/m**3)       0\n",
            "wv (m/s)           0\n",
            "max. wv (m/s)      0\n",
            "wd (deg)           0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = train_data.fillna(method='ffill').fillna(method='bfill')\n",
        "val_data = val_data.fillna(method='ffill').fillna(method='bfill')\n",
        "test_data = test_data.fillna(method='ffill').fillna(method='bfill')\n"
      ],
      "metadata": {
        "id": "YdWaB1zf5q0J",
        "outputId": "9d166012-74e8-41c8-bc6f-9762cd4cd563",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "YdWaB1zf5q0J",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-1135443180>:1: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  train_data = train_data.fillna(method='ffill').fillna(method='bfill')\n",
            "<ipython-input-10-1135443180>:2: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  val_data = val_data.fillna(method='ffill').fillna(method='bfill')\n",
            "<ipython-input-10-1135443180>:3: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  test_data = test_data.fillna(method='ffill').fillna(method='bfill')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_tf_dataset(data, lookback, delay, step, batch_size=128):\n",
        "    # Exclude timestamp column\n",
        "    data_array = data.iloc[:, 1:].to_numpy(dtype=np.float32)\n",
        "    targets = data_array[:, 0]  # example target: first numeric column\n",
        "\n",
        "    dataset = tf.keras.utils.timeseries_dataset_from_array(\n",
        "        data=data_array[:-delay],\n",
        "        targets=targets[lookback + delay:],\n",
        "        sequence_length=lookback // step,\n",
        "        sequence_stride=1,\n",
        "        sampling_rate=step,\n",
        "        batch_size=batch_size\n",
        "    )\n",
        "    return dataset\n"
      ],
      "metadata": {
        "id": "Fx_bmPJB50tl"
      },
      "id": "Fx_bmPJB50tl",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop timestamp column for normalization and dataset creation\n",
        "# (Assuming it is first column)\n",
        "\n",
        "# Fill missing values\n",
        "train_data = train_data.fillna(method='ffill').fillna(method='bfill')\n",
        "val_data = val_data.fillna(method='ffill').fillna(method='bfill')\n",
        "test_data = test_data.fillna(method='ffill').fillna(method='bfill')\n",
        "\n",
        "# Normalize numeric columns only (exclude timestamp)\n",
        "mean = train_data.iloc[:, 1:].mean()\n",
        "std = train_data.iloc[:, 1:].std()\n",
        "\n",
        "train_data.iloc[:, 1:] = (train_data.iloc[:, 1:] - mean) / std\n",
        "val_data.iloc[:, 1:] = (val_data.iloc[:, 1:] - mean) / std\n",
        "test_data.iloc[:, 1:] = (test_data.iloc[:, 1:] - mean) / std\n"
      ],
      "metadata": {
        "id": "kaH87lQX52Af",
        "outputId": "52a90415-91cb-441c-ade4-ddb68b7bb79e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "kaH87lQX52Af",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-3502151183>:5: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  train_data = train_data.fillna(method='ffill').fillna(method='bfill')\n",
            "<ipython-input-12-3502151183>:6: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  val_data = val_data.fillna(method='ffill').fillna(method='bfill')\n",
            "<ipython-input-12-3502151183>:7: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  test_data = test_data.fillna(method='ffill').fillna(method='bfill')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "batch_size = 128\n",
        "lookback = 720\n",
        "delay = 72\n",
        "step = 6\n",
        "\n",
        "train_dataset = create_tf_dataset(train_data, lookback, delay, step, batch_size)\n",
        "val_dataset = create_tf_dataset(val_data, lookback, delay, step, batch_size)\n",
        "test_dataset = create_tf_dataset(test_data, lookback, delay, step, batch_size)\n"
      ],
      "metadata": {
        "id": "d5YPEKz03wKQ"
      },
      "id": "d5YPEKz03wKQ",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "# Assume lookback, step, etc. defined as before\n",
        "\n",
        "# input_shape = (sequence_length, number_of_features)\n",
        "input_shape = (lookback // step, train_data.shape[1] - 1)  # exclude timestamp col\n",
        "\n",
        "model = Sequential([\n",
        "    LSTM(32, input_shape=input_shape),\n",
        "    Dropout(0.2),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='mae', metrics=['mae'])\n",
        "\n",
        "# Train using the tf.data.Dataset objects, not numpy arrays\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=10,\n",
        "    validation_data=val_dataset\n",
        ")\n",
        "\n",
        "# Evaluate on test dataset\n",
        "model.evaluate(test_dataset)\n"
      ],
      "metadata": {
        "id": "xEpoYG_W4Bo1",
        "outputId": "419a515c-c7f7-4f99-8b82-f6992a9dc99d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "xEpoYG_W4Bo1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2294/2294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 97ms/step - loss: 0.4653 - mae: 0.4653 - val_loss: 0.3776 - val_mae: 0.3776\n",
            "Epoch 2/10\n",
            "\u001b[1m2294/2294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 94ms/step - loss: 0.3637 - mae: 0.3637 - val_loss: 0.3483 - val_mae: 0.3483\n",
            "Epoch 3/10\n",
            "\u001b[1m2294/2294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 101ms/step - loss: 0.3424 - mae: 0.3424 - val_loss: 0.3434 - val_mae: 0.3434\n",
            "Epoch 4/10\n",
            "\u001b[1m2294/2294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 94ms/step - loss: 0.3313 - mae: 0.3313 - val_loss: 0.3399 - val_mae: 0.3399\n",
            "Epoch 5/10\n",
            "\u001b[1m2294/2294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 92ms/step - loss: 0.3242 - mae: 0.3242 - val_loss: 0.3317 - val_mae: 0.3317\n",
            "Epoch 6/10\n",
            "\u001b[1m2021/2294\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m22s\u001b[0m 82ms/step - loss: 0.3194 - mae: 0.3194"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    x_train, y_train,\n",
        "    epochs=20,\n",
        "    batch_size=128,\n",
        "    validation_data=(x_val, y_val)\n",
        ")\n"
      ],
      "metadata": {
        "id": "J1RN0lJk4D6R"
      },
      "id": "J1RN0lJk4D6R",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_mae = model.evaluate(x_test, y_test)\n",
        "print(f'Test MAE: {test_mae}')\n"
      ],
      "metadata": {
        "id": "mIgvogTK4F2P"
      },
      "id": "mIgvogTK4F2P",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}